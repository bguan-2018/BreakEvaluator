{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonFileHandler():\n",
    "        \n",
    "    def save(self, data, filename):\n",
    "        with open(filename, 'w') as outfile:\n",
    "            json.dump(data, outfile)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "CONSUMER_KEY = 'Gk01VFusznFm3LkalewiOfA5v'\n",
    "CONSUMER_SECRET = 'Sd3bbCjgj1qL3FDpLPakRYIFnY9292BahmgMshiymvFBbgjb1H'\n",
    "ACCESS_TOKEN = '1240359846219788289-GRJvVirIxaQbGjOG9CRP35bkOXSmHA'\n",
    "ACCESS_TOKEN_SECRET = 'dQzgiPTzIevCUi93mZ1CtozZgKvXDtNjzPJPC4EgCZpba'\n",
    "\n",
    "\n",
    "# Ignore this class\n",
    "class AgeDetector():\n",
    "    \n",
    "    def __init__(self):\n",
    "        auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "        auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "        api = tweepy.API(auth)\n",
    "        \n",
    "    def get_age(self, name):\n",
    "\n",
    "        user = api.get_user(name)\n",
    "        ageTwitterAccount = user.created_at\n",
    "        \n",
    "    def is_over_limit(self, account_age, min_age, max_age):\n",
    "        if min_age <= account_age <= max_age:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from emotion_predictor import EmotionPredictor\n",
    "\n",
    "\n",
    "# Have to force keras to use theanos\n",
    "class BreakEmotionPredictor():\n",
    "    \n",
    "    def __init__(self):\n",
    "#         There are 3 modes:\n",
    "#             1. ekman\n",
    "#             2. plutchik\n",
    "#             3. poms\n",
    "#         I recommend using the mc (multiclass) mode, because multilabel won't produce a probablity table\n",
    "        self.ekman_model = EmotionPredictor(classification='ekman', setting='mc')\n",
    "        self.plutchik_model = EmotionPredictor(classification='plutchik', setting='mc')\n",
    "        self.poms_model = EmotionPredictor(classification='poms', setting='mc')\n",
    "        \n",
    "    def predict(self, tweets):\n",
    "\n",
    "        tweet_texts = [t['full_text'] for u, t in tweets.items()] \n",
    "        ekman_probabilities = self.ekman_model.predict_probabilities(tweet_texts)\n",
    "        plutchik_probabilities = self.plutchik_model.predict_probabilities(tweet_texts)\n",
    "        poms_probabilities = self.poms_model.predict_probabilities(tweet_texts)\n",
    "        users = list(tweets.keys())\n",
    "        ekman_prob_dict = {}\n",
    "        for index, value in ekman_probabilities.drop(['Tweet'], axis=1).to_dict('index').items():\n",
    "            ekman_prob_dict[users[index]] = value\n",
    "        plutchik_prob_dict = {}\n",
    "        for index, value in plutchik_probabilities.drop(['Tweet'], axis=1).to_dict('index').items():\n",
    "            plutchik_prob_dict[users[index]] = value\n",
    "        poms_prob_dict = {}\n",
    "        for index, value in poms_probabilities.drop(['Tweet'], axis=1).to_dict('index').items():\n",
    "            poms_prob_dict[users[index]] = value\n",
    "        return ekman_prob_dict, plutchik_prob_dict, poms_prob_dict\n",
    "    \n",
    "    def get_label(self, probabilities):\n",
    "        labels = {}\n",
    "        for tweet_id, probability in probabilities.items():\n",
    "            max_prob = 0\n",
    "            label = ''\n",
    "            for emotion, value in probability.items():\n",
    "                if value > max_prob:\n",
    "                    max_prob = value\n",
    "                    label = emotion\n",
    "            labels[tweet_id] = label\n",
    "        return labels\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "#     predictor = BreakEmotionPredictor()\n",
    "#     probabilities = predictor.predict([{'id': '123', 'text':'I want to take a break.'}])\n",
    "#     print(predictor.get_label(probabilities))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class BreakReasonPredictor():\n",
    "\n",
    "#     These definitions will not produce the most accurate results\n",
    "    PRIVACY_DEFINITION = '.*(privacy|leak|secret|intimacy|personal).*'\n",
    "    UNPRODUCTIVE_DEFINITION = '.*(productive|productivity|unproductive).*'\n",
    "    BANALITY_DEFINITION = '.*(bored|boring|tired|tiring).*'\n",
    "    ADDICTION_DEFINITION = '.*(addict| can\\'t stop).*'\n",
    "    PRESSURE_DEFINITION = '.*(pressure|force).*'\n",
    "    \n",
    "    \n",
    "    def predict(self, tweets):\n",
    "        \n",
    "        reasons = {}\n",
    "        for user, tweet in tweets.items():\n",
    "            text = tweet['full_text'].lower()\n",
    "            if re.search(self.PRIVACY_DEFINITION, text):\n",
    "                reasons[user] = 'PRIVACY'\n",
    "            elif re.search(self.UNPRODUCTIVE_DEFINITION, text):\n",
    "                reasons[user] = 'PRODUCTIVITY'\n",
    "            elif re.search(self.BANALITY_DEFINITION, text):\n",
    "                reasons[user] = 'BANALITY'\n",
    "            elif re.search(self.ADDICTION_DEFINITION, text):\n",
    "                reasons[user] = 'ADDICTION'\n",
    "            elif re.search(self.PRESSURE_DEFINITION, text):\n",
    "                reasons[user] = 'PRESSURE'\n",
    "            else:\n",
    "                reasons[user] = 'UNKNOWN'\n",
    "        return reasons\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class NoiseFilter():\n",
    "    \n",
    "    BREAK_DEFINITION = '.*(?!(don\\'t|do not)).*(consider|wanna|consider|going to|gonna|want|will|am|should) (?!not).*(take|taking).*break.*from twitter'\n",
    "    \n",
    "    def is_break(self, tweet):\n",
    "        text = tweet['full_text'].lower()\n",
    "        if re.search(self.BREAK_DEFINITION, text):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "{'RealMuffnSlayr': 'UNKOWNN', 'organiclixie': 'UNKOWNN', 'zenox_o': 'UNKOWNN', 'BuckwaterArthur': 'UNKOWNN', 'MadMaxLowry': 'UNKOWNN', 'YNGICLIT': 'UNKOWNN', '2JamJar2': 'UNKOWNN', 'AlanisBeitia': 'UNKOWNN', 'kookiesbananana': 'UNKOWNN', 'stupeio': 'UNKOWNN', 'Lazarbeam': 'UNKOWNN', 'the_donut611': 'UNKOWNN', 'Rintarxu': 'UNKOWNN', 'gaypigeon1': 'UNKOWNN', 'fruitscented': 'BANALITY', 'fletchersjen': 'UNKOWNN', 'MrBenJ5': 'UNKOWNN'}\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "import tweepy \n",
    "import re\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.parser import parse\n",
    "\n",
    "#Variables that contains the user credentials to access Twitter API \n",
    "CONSUMER_KEY = 'Gk01VFusznFm3LkalewiOfA5v'\n",
    "CONSUMER_SECRET = 'Sd3bbCjgj1qL3FDpLPakRYIFnY9292BahmgMshiymvFBbgjb1H'\n",
    "ACCESS_TOKEN = '1240359846219788289-GRJvVirIxaQbGjOG9CRP35bkOXSmHA'\n",
    "ACCESS_TOKEN_SECRET = 'dQzgiPTzIevCUi93mZ1CtozZgKvXDtNjzPJPC4EgCZpba'\n",
    "\n",
    "#This is a basic listener that just prints received tweets to stdout.\n",
    "class BreakUserSearcher():\n",
    "    \n",
    "    def __init__(self):\n",
    "        auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "        auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "        self.api = tweepy.API(auth)\n",
    "        self.until_date=datetime.datetime(2020, 1, 1)\n",
    "        self.max_break_tweets = 1000\n",
    "        self.max_per_user_tweets_before_break = 100\n",
    "        self.max_per_user_tweets_after_break = 1\n",
    "        self.break_query = 'take break from twitter'\n",
    "        self.filter = NoiseFilter()\n",
    "        self.emotion_predictor = BreakEmotionPredictor()\n",
    "        self.reason_predictor = BreakReasonPredictor()\n",
    "#     User set\n",
    "\n",
    "        self.tweets = {}\n",
    "        self.user_break_tweet_date = {}\n",
    "        self.user_break_tweet_id = {}        \n",
    "        self.user_break_tweet_reason = {}\n",
    "        \n",
    "        self.user_emotions_probabilities_after_break_ekman = {}\n",
    "        self.user_emotions_probabilities_after_break_plutchik = {}\n",
    "        self.user_emotions_probabilities_after_break_poms = {}\n",
    "        \n",
    "        self.user_emotions_labels_after_break_ekman = {}\n",
    "        self.user_emotions_labels_after_break_plutchik = {}\n",
    "        self.user_emotions_labels_after_break_poms = {}\n",
    "        \n",
    "        self.user_emotions_after_break = {}\n",
    "        self.user_tweets_after_break = {}\n",
    "        \n",
    "        self.user_tweets_break_gap = {}\n",
    "        self.user_tweets_before_count = {}\n",
    "           \n",
    "#     collects the tweets that mentioned break\n",
    "    def collect(self):\n",
    "#         Remove Status object\n",
    "#         No one week old tweets will be returned \n",
    "        tweets = tweepy.Cursor(self.api.search, q=self.break_query, tweet_mode=\"extended\", wait_on_rate_limit=True).items(self.max_break_tweets)\n",
    "        for t in list(tweets):\n",
    "#             print(t)\n",
    "            tweet_json = t._json\n",
    "            if self.filter.is_break(tweet_json):\n",
    "                self.tweets[t.user.screen_name]=tweet_json\n",
    "        \n",
    "#     Extract the date that the user wanted to take the break\n",
    "    def extract_user_break_information(self):\n",
    "        for user, tweet in self.tweets.items():\n",
    "                self.user_break_tweet_date[user] = tweet['created_at']\n",
    "                self.user_break_tweet_id[user] = tweet['id'] \n",
    "            \n",
    "#     Extract the first tweet that the user tweeted right after the mention of taking a break\n",
    "    def extract_user_tweets_after_break(self):\n",
    "        for user, break_tweet_id in self.user_break_tweet_id.items():\n",
    "            user_tweets = tweepy.Cursor(self.api.user_timeline, screen_name=user, since_id=break_tweet_id, tweet_mode=\"extended\", wait_on_rate_limit=True).items(self.max_per_user_tweets_after_break)\n",
    "            tweets_after_break = []\n",
    "#             print(user_tweets)\n",
    "            for tweet in user_tweets:\n",
    "#                 if self.user_tweets_after_break[user] == None:\n",
    "#                 print(user+': '+str(tweet.created_at))\n",
    "                tweets_after_break.append(tweet._json)\n",
    "#             print(tweets_after_break)\n",
    "            self.user_tweets_after_break[user] = tweets_after_break  \n",
    "    \n",
    "    \n",
    "#     Count how many tweets the users tweeted before the break\n",
    "    def extract_user_tweets_before_count(self):\n",
    "        for user, break_tweet_id in self.user_break_tweet_id.items():\n",
    "            user_tweets = tweepy.Cursor(self.api.user_timeline, screen_name=user, max_id=break_tweet_id, tweet_mode=\"extended\", wait_on_rate_limit=True).items(self.max_per_user_tweets_before_break)\n",
    "            tweets_before_break = []\n",
    "#             print(user_tweets)\n",
    "            for tweet in user_tweets:\n",
    "                if tweet.created_at.replace(tzinfo=None) > (parse(self.user_break_tweet_date[user]).replace(tzinfo=None)-timedelta(days=7)): \n",
    "                    tweets_before_break.append(tweet._json)\n",
    "            self.user_tweets_before_count[user] = len(tweets_before_break)\n",
    "        \n",
    "    def extract_user_emotions_after_break(self):\n",
    "        self.user_emotions_probabilities_after_break_ekman, self.user_emotions_probabilities_after_break_plutchik, self.user_emotions_probabilities_after_break_poms = self.emotion_predictor.predict(self.tweets)\n",
    "        self.user_emotions_labels_after_break_ekman = self.emotion_predictor.get_label(self.user_emotions_probabilities_after_break_ekman)\n",
    "        self.user_emotions_labels_after_break_plutchik = self.emotion_predictor.get_label(self.user_emotions_probabilities_after_break_plutchik)\n",
    "        self.user_emotions_labels_after_break_poms = self.emotion_predictor.get_label(self.user_emotions_probabilities_after_break_poms)\n",
    "\n",
    "    def extract_user_break_reason(self):\n",
    "        self.user_break_tweet_reason = self.reason_predictor.predict(self.tweets)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    break_searcher = BreakUserSearcher()\n",
    "    break_searcher.collect()\n",
    "    print(len(break_searcher.tweets))\n",
    "#     print(break_searcher.tweets)\n",
    "    break_searcher.extract_user_break_information()\n",
    "    break_searcher.extract_user_tweets_after_break()\n",
    "    break_searcher.extract_user_tweets_before_count()\n",
    "    break_searcher.extract_user_break_reason()\n",
    "    break_searcher.extract_user_emotions_after_break()\n",
    " \n",
    "    \n",
    "#     print(break_searcher.user_break_tweet_date)\n",
    "#     print(break_searcher.user_break_tweet_id)\n",
    "#     print(break_searcher.user_tweets_after_break)\n",
    "\n",
    "    print(break_searcher.user_break_tweet_reason)\n",
    "\n",
    "#     print(break_searcher.user_emotions_probabilities_after_break_ekman)\n",
    "#     print(break_searcher.user_emotions_labels_after_break_ekman)\n",
    "\n",
    "    json_file_handler = JsonFileHandler()\n",
    "    json_file_handler.save(break_searcher.tweets, 'break_tweets.json')\n",
    "#     json_file_handler.save(break_searcher.user_tweets_after_break, 'break_tweets_after.json')\n",
    "#     json_file_handler.save(break_searcher.user_tweets_before_count, 'break_tweets_before_count.json')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
